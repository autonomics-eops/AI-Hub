<policies>
    <inbound>
        <!-- Return static response for /models? call -->
        <include-fragment fragment-id="frag-models-list" />
        <!-- Return static response for /deployments? call -->
        <include-fragment fragment-id="frag-deployments-list" />
        <base />
        <!-- AAD Authorization -->
        <!-- Enabled if entra-validate named value is set to true -->
        <include-fragment fragment-id="frag-aad-auth" />
        <!-- Detecting streaming request to adjust token calculations -->
        <choose>
            <when condition="@(context.Request.Body.As<JObject>(true)["stream"] != null && context.Request.Body.As<JObject>(true)["stream"].Type != JTokenType.Null)">
                <set-variable name="isStream" value="@{
                    var content = (context.Request.Body?.As<JObject>(true));
                    string streamValue = content["stream"].ToString().ToLower();
                    return streamValue;
                }" />
            </when>
        </choose>
        <!-- Deleting api-key header to it is not passed to OpenAI endpoint-->
        <set-header name="api-key" exists-action="delete" />
        <!-- Setting cache keys -->
        <set-variable name="deployment-id" value="@((string)context.Request.MatchedParameters["deployment-id"])" />
        <!-- Inherit Model based restrictions -->
        <include-fragment fragment-id="frag-model-rbac" />
        <set-variable name="cache-variable" value="{{cache-version}}" />
        <set-variable name="routesCacheKey"
            value="@((string)context.Variables["deployment-id"]
            + "Routes"
            + context.Deployment.Region
            + context.Api.Revision
            + context.Variables.GetValueOrDefault<string>("cache-variable", "v2025"))" />
        <set-variable name="oaClustersCacheKey" 
            value="@("oaClusters" 
                + context.Deployment.Region 
                + context.Api.Revision 
                + context.Variables.GetValueOrDefault<string>("cache-variable", "v2025"))" />
                
        <!-- Getting OpenAI clusters configuration -->
        <cache-lookup-value key="@((string)context.Variables.GetValueOrDefault<string>("oaClustersCacheKey", "ALL-CLUSTERS"))" variable-name="oaClusters" />
        <!-- If we can't find the configuration cached, it will be loaded -->
        <choose>
            <when condition="@(context.Variables.ContainsKey("oaClusters") == false)">
                <set-variable name="oaClusters" value="@{
                        // route is an Azure OpenAI API endpoints
                        JArray routes = new JArray();
                        // cluster is a group of routes that are capable of serving a specific deployment name (model and version)
                        JArray clusters = new JArray();
                        // Update the below if condition when using multiple APIM gateway regions/SHGW to get different configuartions for each region
                        if(context.Deployment.Region == "West Europe" || true)
                        {
                            // Adding all Azure OpenAI endpoints routes (which are set as APIM Backend)
                            routes.Add(new JObject()
                            {
                                { "name", "OpenAI001" },
                                { "location", "West Europe" },
                                { "backend-id", "backend-openai-001" },
                                { "priority", 1},
                                { "isThrottling", true }, 
                                { "retryAfter", DateTime.MinValue } 
                            });

                            // For each deployment name, create a cluster with the routes that can serve it
                            // It is important in you OpenAI deployments to use the same name across instances
                            clusters.Add(new JObject()
                            {
                                { "deploymentName", "chat" },
                                { "routes", new JArray(routes[0]) }
                            });

                            clusters.Add(new JObject()
                            {
                                { "deploymentName", "embedding" },
                                { "routes", new JArray(routes[0]) }
                            });

                            clusters.Add(new JObject()
                            {
                                { "deploymentName", "gpt-4o" },
                                { "routes", new JArray(routes[0]) }
                            });

                            clusters.Add(new JObject()
                            {
                                { "deploymentName", "text-embedding-ada-002" },
                                { "routes", new JArray(routes[0]) }
                            });

                            clusters.Add(new JObject()
                            {
                                { "deploymentName", "gpt-41" },
                                { "routes", new JArray(routes[0]) }
                            });

                            clusters.Add(new JObject()
                            {
                                { "deploymentName", "gpt-41-mini" },
                                { "routes", new JArray(routes[0]) }
                            });

                            clusters.Add(new JObject()
                            {
                                { "deploymentName", "gpt-41-nano" },
                                { "routes", new JArray(routes[0]) }
                            });
                            
                        }
                        else
                        {
                            //No clusters found for selected region, either return error (defult behavior) or set default cluster in the else section
                        }
                        
                        return clusters;   
                    }" />
                <!-- Add cluster configurations to cache -->
                <cache-store-value key="@((string)context.Variables.GetValueOrDefault<string>("oaClustersCacheKey", "ALL-CLUSTERS"))" value="@((JArray)context.Variables["oaClusters"])" duration="86400" />
            </when>
        </choose>
        <include-fragment fragment-id="frag-validate-routes" />
        <!-- Backend Managed Identity -->
        <authentication-managed-identity resource="https://cognitiveservices.azure.com" output-token-variable-name="msi-access-token" client-id="{{uami-client-id}}" ignore-error="false" />
        <set-header name="Authorization" exists-action="override">
            <value>@("Bearer " + (string)context.Variables["msi-access-token"])</value>
        </set-header>
        <!-- Setting gobal TPM limit to collect usage for streaming requests -->
        <include-fragment fragment-id="frag-token-limits" />
        <!-- Handling usage for streaming requests -->
        <include-fragment fragment-id="frag-openai-usage-streaming" />
    </inbound>
    <backend>
        <include-fragment fragment-id="frag-backend-routing" />
    </backend>
    <outbound>
        <base />
        <!-- Handling usage for non-streaming requests -->
        <include-fragment fragment-id="frag-openai-usage" />
    </outbound>
    <on-error>
        <base />
        <!-- This is used to push custom metrics related to 429 throttleing errors -->
        <!-- It is designed to premit setting up Azure Monitor Alerts notifying the team of potential service degredation -->
        <set-variable name="service-name" value="Azure Open AI" />
        <set-variable name="target-deployment" value="@((string)context.Request.MatchedParameters["deployment-id"])" />
        <include-fragment fragment-id="frag-throttling-events" />
    </on-error>
</policies>